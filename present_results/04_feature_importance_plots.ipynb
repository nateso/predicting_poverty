{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b1f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db0797",
   "metadata": {},
   "source": [
    "## run baseline models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc25a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the necessary functions from the analysis package\n",
    "\n",
    "# load the variable names, this allows to access the variables in the feature data in a compact way\n",
    "from analysis_utils.variable_names import *\n",
    "\n",
    "# load flagged ids \n",
    "from analysis_utils.flagged_uids import flagged_uids\n",
    "\n",
    "# load the functions to do spatial k-fold CV\n",
    "from analysis_utils.spatial_CV import split_lsms_spatial\n",
    "\n",
    "# load the helper functions\n",
    "from analysis_utils.analysis_helpers import *\n",
    "\n",
    "# load the random forest trainer and cross_validator\n",
    "import analysis_utils.RandomForest as rf\n",
    "\n",
    "# load the combien model\n",
    "from analysis_utils.CombinedModel import CombinedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee47dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the global file paths\n",
    "root_data_dir = \"../../Data\"\n",
    "\n",
    "# the lsms data\n",
    "lsms_pth = f\"{root_data_dir}/lsms/processed/labels_cluster_v1.csv\"\n",
    "\n",
    "# the feature data\n",
    "feat_data_pth = f\"{root_data_dir}/feature_data/tabular_data.csv\"\n",
    "\n",
    "# set the random seed\n",
    "random_seed = 423\n",
    "spatial_cv_random_seed = 348\n",
    "\n",
    "# set the number of folds for k-fold CV\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63210787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, specified test ratio: 0.2 - Actual test ratio 0.20\n",
      "Fold 1, specified test ratio: 0.2 - Actual test ratio 0.20\n",
      "Fold 2, specified test ratio: 0.2 - Actual test ratio 0.21\n",
      "Fold 3, specified test ratio: 0.2 - Actual test ratio 0.20\n",
      "Fold 4, specified test ratio: 0.2 - Actual test ratio 0.19\n",
      "Number of observations 6401\n",
      "Number of clusters 2128\n",
      "Number of x vars 109\n"
     ]
    }
   ],
   "source": [
    "# load the feature and the label data\n",
    "lsms_df = pd.read_csv(lsms_pth)\n",
    "# remove flagged ids form dataset\n",
    "lsms_df = lsms_df[~lsms_df.unique_id.isin(flagged_uids)].reset_index()\n",
    "lsms_df['avg_log_mean_pc_cons_usd_2017'] = lsms_df.groupby('cluster_id')['log_mean_pc_cons_usd_2017'].transform('mean')\n",
    "lsms_df['avg_mean_asset_index_yeh'] = lsms_df.groupby('cluster_id')['mean_asset_index_yeh'].transform('mean')\n",
    "feat_df = pd.read_csv(feat_data_pth)\n",
    "\n",
    "# merge the label and the feature data to one dataset\n",
    "lsms_vars = ['unique_id', 'n_households',           \n",
    "             'log_mean_pc_cons_usd_2017', 'avg_log_mean_pc_cons_usd_2017',\n",
    "             'mean_asset_index_yeh', 'avg_mean_asset_index_yeh']\n",
    "df = pd.merge(lsms_df[lsms_vars], feat_df, on = 'unique_id', how = 'left')\n",
    "\n",
    "# get the training and validation split\n",
    "fold_ids = split_lsms_spatial(lsms_df, n_folds = n_folds, random_seed = spatial_cv_random_seed)\n",
    "\n",
    "# describe the training data broadly\n",
    "print(f\"Number of observations {len(lsms_df)}\")\n",
    "print(f\"Number of clusters {len(np.unique(lsms_df.cluster_id))}\")\n",
    "print(f\"Number of x vars {len(feat_df.columns)-2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96221c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the within and between x variables\n",
    "avg_rs_vars = avg_ndvi_vars + avg_ndwi_gao_vars + avg_nl_vars\n",
    "osm_vars = osm_dist_vars + osm_count_vars + osm_road_vars\n",
    "between_x_vars = osm_vars + esa_lc_vars + wsf_vars + avg_rs_vars + avg_preciptiation + median_rgb_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e31417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OSM vars: 25\n",
      "Number of Dyn img vars: 6\n",
      "Number of Static img vars: 10\n",
      "Number of precipiation vars: 1\n",
      "Number of RGB vars: 25\n",
      "Total number of vars - Baseline: 42\n",
      "Total number of vars - Baseline + RGB: 67\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of OSM vars: {len(osm_vars)}\")\n",
    "print(f\"Number of Dyn img vars: {len(avg_rs_vars)}\")\n",
    "print(f\"Number of Static img vars: {len(esa_lc_vars) + len(wsf_vars)}\")\n",
    "print(f\"Number of precipiation vars: {len(avg_preciptiation)}\")\n",
    "print(f\"Number of RGB vars: {len(median_rgb_vars)}\")\n",
    "print(f\"Total number of vars - Baseline: {len(between_x_vars) - len(median_rgb_vars)}\")\n",
    "print(f\"Total number of vars - Baseline + RGB: {len(between_x_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca3a78",
   "metadata": {},
   "source": [
    "### Consumption Expenditure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d70da14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between training\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f21b456d1294c0bab768392c43e8c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training after 228 seconds\n"
     ]
    }
   ],
   "source": [
    "# run Cross validation for consumption expenditure\n",
    "between_target_var = 'avg_log_mean_pc_cons_usd_2017'\n",
    "cl_df = df[['cluster_id', between_target_var] + between_x_vars].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "# normalise the feature data\n",
    "cl_df_norm = standardise_df(cl_df, exclude_cols = [between_target_var])\n",
    "\n",
    "# run the bewtween training\n",
    "print('Between training')\n",
    "baseline_cons = rf.CrossValidator(cl_df_norm, \n",
    "                                            fold_ids, \n",
    "                                            between_target_var, \n",
    "                                            between_x_vars, \n",
    "                                            id_var = 'cluster_id', \n",
    "                                            random_seed = random_seed)\n",
    "baseline_cons.run_cv_training(min_samples_leaf = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68c830",
   "metadata": {},
   "source": [
    "### Asset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9e1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between training\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03e84a0a79b427ebabfec5dca008fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run Cross validation for consumption expenditure\n",
    "between_target_var = 'avg_mean_asset_index_yeh'\n",
    "cl_df = df[['cluster_id', between_target_var] + between_x_vars].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "# normalise the feature data\n",
    "cl_df_norm = standardise_df(cl_df, exclude_cols = [between_target_var])\n",
    "\n",
    "# run the bewtween training\n",
    "print('Between training')\n",
    "baseline_asset = rf.CrossValidator(cl_df_norm, \n",
    "                                            fold_ids, \n",
    "                                            between_target_var, \n",
    "                                            between_x_vars, \n",
    "                                            id_var = 'cluster_id', \n",
    "                                            random_seed = random_seed)\n",
    "baseline_asset.run_cv_training(min_samples_leaf = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594d163",
   "metadata": {},
   "source": [
    "# Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dl consumption and the dl asset results\n",
    "results_dir = \"../analysis/results\"\n",
    "dl_cons_pth = f\"{results_dir}/model_objects/between_cons.pkl\"\n",
    "dl_asset_pth = f\"{results_dir}/model_objects/between_asset.pkl\"\n",
    "\n",
    "with open(dl_cons_pth, 'rb') as f:\n",
    "    dl_cons = pickle.load(f)\n",
    "    \n",
    "with open(dl_asset_pth, 'rb') as f:\n",
    "    dl_asset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b887716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels for the plot\n",
    "\n",
    "rgb_vars = ['median_rgb_pc_'+str(i) for i in range(1,26)]\n",
    "rgb_labels = ['ls pc ' + str(i) for i in range(1,26)]\n",
    "\n",
    "ls_vars = ['ls_feat_'+str(i) for i in range(0,25)]\n",
    "rs_vars = ['rs_feat_'+str(i) for i in range(0,25)]\n",
    "\n",
    "ls_var_labels = ['ls pc '+str(i) for i in range(1,26)]\n",
    "rs_var_labels = ['rs pc '+str(i) for i in range(1,26)]\n",
    "\n",
    "osm_count_labels = [\"# \" + i.split(\"_\")[0] for i in osm_count_vars]\n",
    "osm_dist_labels = [\"D \" + i.split(\"_\")[0] for i in osm_dist_vars]\n",
    "osm_road_labels = [\"road network length\", \"D paved road\", \"D primary road\"]\n",
    "\n",
    "ls_rs_label_dict = dict(zip(ls_vars+rs_vars+rgb_vars,ls_var_labels+rs_var_labels+rgb_labels))\n",
    "osm_label_dict = dict(zip(osm_count_vars + osm_dist_vars + osm_road_vars, osm_count_labels + osm_dist_labels + osm_road_labels))\n",
    "precip_label_dict = {'avg_precipitation':'precipitation'}\n",
    "\n",
    "rs_vars = avg_ndvi_vars + avg_ndwi_gao_vars + avg_nl_vars \n",
    "rs_var_labels = [i.replace('avg_',\"\").replace(\"_\",\" \") for i in rs_vars]\n",
    "wsf_var_labels = [i.replace(\"_\",\" \") for i in wsf_vars]\n",
    "esa_lc_var_labels = esa_lc_vars\n",
    "\n",
    "rs_labels = rs_var_labels + wsf_var_labels + esa_lc_var_labels\n",
    "rs_names = rs_vars + wsf_vars + esa_lc_vars\n",
    "\n",
    "rs_label_dict = dict(zip(rs_names, rs_labels))\n",
    "\n",
    "label_dict = {}\n",
    "\n",
    "# Merge the dictionaries\n",
    "label_dict.update(ls_rs_label_dict)\n",
    "label_dict.update(osm_label_dict)\n",
    "label_dict.update(precip_label_dict)\n",
    "label_dict.update(rs_label_dict)\n",
    "\n",
    "# change by hand some\n",
    "label_dict['fuel_dist'] = 'D gas station'\n",
    "label_dict['fuel_count'] = '# gas station'\n",
    "label_dict['avg_ndwi_gao_mean'] = 'ndwi mean'\n",
    "label_dict['avg_ndwi_gao_std'] = 'ndwi std'\n",
    "label_dict['avg_nl_mean'] = 'nightlights mean'\n",
    "label_dict['avg_nl_std'] = 'nightlights std'\n",
    "label_dict['built_up'] = 'built up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a color dictionary\n",
    "ls_color = 'darkred'\n",
    "rs_color = 'teal'\n",
    "remoteness_color = 'sandybrown'\n",
    "amenities_color = 'darkgrey'\n",
    "\n",
    "# create a color for geography (includes WSF, LC, NL)\n",
    "geography_color = 'blueviolet'\n",
    "agriculture_color = 'green'\n",
    "urbanisation_color = 'blue'\n",
    "\n",
    "baseline_colors = {\n",
    "    'agriculture': 'green',\n",
    "    'amenities': 'darkgrey',\n",
    "    'geography': 'blueviolet',\n",
    "    'remoteness': 'sandybrown',\n",
    "    'urbanisation': 'blue'\n",
    "}\n",
    "\n",
    "baseline_ls_colors = {\n",
    "    'agriculture': 'green',\n",
    "    'amenities': 'darkgrey',\n",
    "    'geography': 'blueviolet',\n",
    "    'LS images': 'darkred',\n",
    "    'remoteness': 'sandybrown',\n",
    "    'urbanisation': 'blue'\n",
    "}\n",
    "\n",
    "dl_colors = {\n",
    "    'agriculture': 'green',\n",
    "    'amenities': 'darkgrey',\n",
    "    'LS images': 'darkred',\n",
    "    'RS images': 'teal',\n",
    "    'remoteness': 'sandybrown'\n",
    "}\n",
    "\n",
    "color_dict = {}\n",
    "for k in label_dict.keys():\n",
    "    if 'ls_' in k or '_rgb_' in k:\n",
    "        color_dict[k] = 'darkred'\n",
    "    elif 'rs_' in k:\n",
    "        color_dict[k] = 'teal'\n",
    "    \n",
    "    elif 'count' in k:\n",
    "        color_dict[k] = amenities_color    \n",
    "    elif 'dist' in k or 'road' in k:\n",
    "        color_dict[k] = remoteness_color\n",
    "        if 'road_length' in k:\n",
    "            color_dict[k] = urbanisation_color\n",
    "        \n",
    "    elif 'precipitation' in k:\n",
    "        color_dict[k] = agriculture_color\n",
    "    elif 'ndvi' in k:\n",
    "        color_dict[k] = agriculture_color\n",
    "    elif 'ndwi' in k:\n",
    "        color_dict[k] = agriculture_color\n",
    "    elif 'cropland' in k:\n",
    "        color_dict[k] = agriculture_color\n",
    "    \n",
    "    elif 'wsf_' in k or 'nl_' in k or 'built_' in k:\n",
    "        color_dict[k] = urbanisation_color\n",
    "    else:\n",
    "        color_dict[k] = geography_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the baseline model add rgb to the ls name\n",
    "for k, v in label_dict.items():\n",
    "    if 'ls pc' in v:\n",
    "        new_v = 'rgb' + v\n",
    "        label_dict[k] = 'rgb ' + v\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# get feature importance for the baseline models\n",
    "baseline_cons_feat_importance = baseline_cons.get_feature_importance()\n",
    "baseline_asset_feat_importance = baseline_asset.get_feature_importance()\n",
    "\n",
    "baseline_cons_feat_importance['var_label'] = [label_dict[i] for i in baseline_cons_feat_importance['variable_name']]\n",
    "baseline_asset_feat_importance['var_label'] = [label_dict[i] for i in baseline_asset_feat_importance['variable_name']]\n",
    "\n",
    "baseline_cons_feat_importance['var_col'] = [color_dict[i] for i in baseline_cons_feat_importance['variable_name']]\n",
    "baseline_asset_feat_importance['var_col'] = [color_dict[i] for i in baseline_asset_feat_importance['variable_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish labels and plot data...\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize = (12,16))\n",
    "\n",
    "ax[0].set_ymargin(0.01)\n",
    "ax[0].barh(y = baseline_cons_feat_importance['var_label'],\n",
    "           width = baseline_cons_feat_importance['feat_importance'],\n",
    "           color = baseline_cons_feat_importance['var_col'])    \n",
    "ax[0].spines[['right', 'top']].set_visible(False)\n",
    "ax[0].set_xlabel(\"Relative Feature Importance\")\n",
    "ax[0].set_title('Consumption expenditure')\n",
    "\n",
    "\n",
    "ax[1].set_ymargin(0.01)\n",
    "ax[1].barh(y = baseline_asset_feat_importance['var_label'], \n",
    "           width = baseline_asset_feat_importance['feat_importance'],\n",
    "           color = baseline_asset_feat_importance['var_col'])    \n",
    "ax[1].spines[['right', 'top']].set_visible(False)\n",
    "ax[1].set_xlabel(\"Relative Feature Importance\")\n",
    "ax[1].set_title('Asset wealth index')\n",
    "ax[1].legend()\n",
    "\n",
    "# Create legend handles\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, markersize=10,\n",
    "                      markerfacecolor=color) for label, color in baseline_ls_colors.items()]\n",
    "\n",
    "# Add the legend to the second subplot (ax[1])\n",
    "ax[1].legend(handles=handles, title='Type of feature', loc='lower right')\n",
    "\n",
    "fig.text(0.05,.97,'A',weight = 'bold')\n",
    "fig.text(0.55,.97,'B',weight = 'bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "pth = '../figures/results/baseline_ls_feature_importance.png'\n",
    "plt.savefig(pth, dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ms to ls features\n",
    "for k, v in label_dict.items():\n",
    "    if 'ls pc' in v:\n",
    "        new_v = 'rgb' + v\n",
    "        label_dict[k] = 'ms ' + v[4:]\n",
    "\n",
    "\n",
    "# get feature importance for the deep learning models\n",
    "dl_cons.feat_importance['var_label'] = [label_dict[i] for i in dl_cons.feat_importance['variable_name']]\n",
    "dl_asset.feat_importance['var_label'] = [label_dict[i] for i in dl_asset.feat_importance['variable_name']]\n",
    "\n",
    "dl_cons.feat_importance['var_col'] = [color_dict[i] for i in dl_cons.feat_importance['variable_name']]\n",
    "dl_asset.feat_importance['var_col'] = [color_dict[i] for i in dl_asset.feat_importance['variable_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize = (12,16))\n",
    "\n",
    "ax[0].set_ymargin(0.01)\n",
    "ax[0].barh(y = dl_cons.feat_importance['var_label'], \n",
    "           width = dl_cons.feat_importance['feat_importance'],\n",
    "           color = dl_cons.feat_importance['var_col'])    \n",
    "ax[0].spines[['right', 'top']].set_visible(False)\n",
    "ax[0].set_xlabel(\"Relative Feature Importance\")\n",
    "ax[0].set_title('Consumption expenditure')\n",
    "\n",
    "\n",
    "ax[1].set_ymargin(0.01)\n",
    "ax[1].barh(y = dl_asset.feat_importance['var_label'], \n",
    "           width = dl_asset.feat_importance['feat_importance'],\n",
    "          color = dl_asset.feat_importance['var_col'])    \n",
    "ax[1].spines[['right', 'top']].set_visible(False)\n",
    "ax[1].set_xlabel(\"Mean relative feature importance\")\n",
    "ax[1].set_title('Asset wealth index')\n",
    "\n",
    "# Create legend handles\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, markersize=10,\n",
    "                      markerfacecolor=color) for label, color in dl_colors.items()]\n",
    "\n",
    "# Add the legend to the second subplot (ax[1])\n",
    "ax[1].legend(handles=handles, title='Type of feature', loc='lower right')\n",
    "\n",
    "\n",
    "fig.text(0.05,.99,'A',weight = 'bold', size = 14)\n",
    "fig.text(0.55,.99,'B',weight = 'bold', size = 14)\n",
    "\n",
    "plt.tight_layout()\n",
    "pth = '../figures/results/dl_feature_importance.png'\n",
    "plt.savefig(pth, dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a1e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
