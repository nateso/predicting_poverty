{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c68a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c18345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the torch_framework package\n",
    "from analysis_utils.torch_framework.CrossValidator import CrossValidator\n",
    "from analysis_utils.torch_framework.ResNet18 import *\n",
    "from analysis_utils.torch_framework.torch_helpers import *\n",
    "from analysis_utils.torch_framework.torch_helpers import standardise as torch_standardise\n",
    "from analysis_utils.torch_framework.SatDataset import SatDataset\n",
    "\n",
    "# load the variable names of the tabular feature data\n",
    "from analysis_utils.variable_names import *\n",
    "\n",
    "# import the helpers to demean the data and get the deltas etc. \n",
    "from analysis_utils.analysis_helpers import demean_df, make_delta_df\n",
    "\n",
    "# load the functions to do spatial CV\n",
    "from analysis_utils.spatial_CV import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675b3156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    }
   ],
   "source": [
    "# set the global file paths\n",
    "root_data_dir = \"../../Data\"\n",
    "\n",
    "# the lsms data\n",
    "lsms_pth = f\"{root_data_dir}/lsms/processed/labels_cluster_v1.csv\"\n",
    "\n",
    "# the feature data (OSM + precipitation)\n",
    "# could also include precipication data (but this is most likely covered by the NDWI) and furthermore,\n",
    "# it would require to add an additional model step (combining the precipitation data and the sat features...)\n",
    "# feat_data_pth = f\"{root_data_dir}/feature_data/tabular_data.csv\"\n",
    "\n",
    "# set the random seed\n",
    "random_seed = 348\n",
    "\n",
    "# set the number of folds for k-fold CV\n",
    "n_folds = 2\n",
    "\n",
    "# set the number of epochs\n",
    "n_epochs = 2\n",
    "\n",
    "# training device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f413d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths for the satellite image satistics\n",
    "sat_img_dir = f\"{root_data_dir}/satellite_imgs\"\n",
    "\n",
    "# define the delta image directory (includes demeaned images)\n",
    "delta_img_dir = f\"{sat_img_dir}/RS_v2/RS_v2_delta\"\n",
    "delta_stats_pth = f\"{sat_img_dir}/RS_v2/RS_v2_delta_img_stats.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592ab4e",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64cd31a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Delta DF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278eddb757ba4f7ca8eadc35d391b520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the LSMS data\n",
    "lsms_df = pd.read_csv(lsms_pth).iloc[:100,:]\n",
    "\n",
    "cl_df = lsms_df[['cluster_id', 'country', 'lat', 'lon']].copy().drop_duplicates().reset_index(drop = True)\n",
    "within_df = lsms_df[['cluster_id', 'unique_id', 'log_mean_pc_cons_usd_2017']]\n",
    "\n",
    "# demean the df\n",
    "demeaned_df = demean_df(within_df)\n",
    "demeaned_df = demeaned_df.rename(columns = {'unique_id':'delta_id'})\n",
    "demeaned_df = pd.merge(demeaned_df, cl_df, on = 'cluster_id', how = 'left')\n",
    "\n",
    "# create delta df\n",
    "print(\"Make Delta DF\")\n",
    "delta_df = make_delta_df(within_df)\n",
    "delta_df = pd.merge(delta_df, cl_df, on = 'cluster_id', how = 'left')\n",
    "\n",
    "# add the demeaned df to the delta df\n",
    "aux = demeaned_df.copy().rename(columns = {'unique_id': 'delta_id'})\n",
    "delta_df = pd.concat([delta_df, demeaned_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c1b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, specified test ratio: 0.5 - Actual test ratio 0.50\n",
      "Fold 1, specified test ratio: 0.5 - Actual test ratio 0.50\n"
     ]
    }
   ],
   "source": [
    "# get the fold ids from spatial CV\n",
    "fold_ids = split_lsms_spatial(lsms_df, n_folds = n_folds, random_seed = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93983ac3",
   "metadata": {},
   "source": [
    "# Demeaned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6910a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable\n",
    "demeaned_target_var = 'log_mean_pc_cons_usd_2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ec19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image statistics for the demeaned images\n",
    "demeaned_img_stats = get_agg_img_stats(delta_stats_pth, demeaned_df, id_var = 'delta_id')\n",
    "demeaned_feat_stats = get_feat_stats(demeaned_img_stats)\n",
    "\n",
    "# get the target stats\n",
    "demeaned_target_stats = get_target_stats(demeaned_df, demeaned_target_var)\n",
    "\n",
    "# define the transforms\n",
    "# get the data transforms for the target --> is used in the DataLoader object\n",
    "demeaned_target_transform = transforms.Compose([\n",
    "        torchvision.transforms.Lambda(lambda t: torch_standardise(t, demeaned_target_stats['mean'], demeaned_target_stats['std'])),\n",
    "    ])\n",
    "\n",
    "# get the data transform for the Landsat image (normalisation and random horizontal + vertical flips)\n",
    "demeaned_feat_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomVerticalFlip(.5),\n",
    "    torchvision.transforms.RandomHorizontalFlip(.5),\n",
    "    transforms.Normalize(demeaned_feat_stats['mean'], demeaned_feat_stats['std'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48f5d5",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddad2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'within_cons_demeaned'\n",
    "cv_object_name = 'within_cons_demeaned_cv'\n",
    "data_type = 'RS_v2'\n",
    "id_var = 'delta_id'\n",
    "\n",
    "# set settings for the ResNet\n",
    "input_channels = 4\n",
    "ms = False\n",
    "random_weights = True\n",
    "\n",
    "# set hyper-parameters\n",
    "hyper_params = {\n",
    "    'lr': 1e-2,\n",
    "    'batch_size': 128,\n",
    "    'alpha': 1e-2,\n",
    "    'step_size': 1,\n",
    "    'gamma': 0.96,\n",
    "    'n_epochs': n_epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48271cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into RAM first\n",
    "# this reduces training times by ~60%...\n",
    "_dat = SatDataset(demeaned_df, delta_img_dir, data_type,\n",
    "                  demeaned_target_var, id_var,\n",
    "                  demeaned_feat_transform, demeaned_target_transform)\n",
    "_loader = DataLoader(_dat, batch_size = hyper_params['batch_size'], shuffle = False)\n",
    "_, _ = next(iter(_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c5f4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be5b41c92a34483b415672e9656340d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 0\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462820917c7a4235ac5277686705a614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 1.8473 - Train R2 -0.2278 - Val MSE: 16041940619949506560.0000 - Val R2 -60691460168588320768.0000\n",
      "\tEPOCH 1 - Train MSE: 481.4398 - Train R2 -318.9831 - Val MSE: 927789440040960.0000 - Val R2 -3510105321484388.5000\n",
      "Finished training after 27 seconds\n",
      "Lowest loss on validation set in epoch 1: 927789440040960.000000\n",
      "Maximum R2 on validation set in epoch 1: -3510105321484388.500000\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c605181ee11c4eb4961a57012d3e3dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 1\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52481b71f70744bf81a02c9e9f1d1645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 0.9881 - Train R2 -0.3356 - Val MSE: 745447580594339840.0000 - Val R2 -857666476063516416.0000\n",
      "\tEPOCH 1 - Train MSE: 520.7944 - Train R2 -702.9431 - Val MSE: 2301825713700864.0000 - Val R2 -2648340364346970.5000\n",
      "Finished training after 27 seconds\n",
      "Lowest loss on validation set in epoch 1: 2301825713700864.000000\n",
      "Maximum R2 on validation set in epoch 1: -2648340364346970.500000\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656a6fd52e654e5e9c0ad90c19934d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Cross-validation after 64 seconds\n"
     ]
    }
   ],
   "source": [
    "# initialise the model and the CrossValidator object\n",
    "ResNet18 = init_resnet(input_channels, ms, random_weights, random_seed = random_seed)\n",
    "demeaned_cv = CrossValidator(model = ResNet18,\n",
    "                            lsms_df = demeaned_df,\n",
    "                            fold_ids = fold_ids,\n",
    "                            img_dir = delta_img_dir,\n",
    "                            data_type = data_type,\n",
    "                            target_var = demeaned_target_var,\n",
    "                            id_var = id_var,\n",
    "                            feat_transform = demeaned_feat_transform,\n",
    "                            target_transform = demeaned_target_transform,\n",
    "                            device = device,\n",
    "                            model_name = model_name,\n",
    "                            random_seed = random_seed)\n",
    "\n",
    "# run k-fold-cv\n",
    "demeaned_cv.run_cv(hyper_params)\n",
    "\n",
    "# save the cv object\n",
    "demeaned_cv.save_object(name = cv_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d991729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -3442083925671059.0, 'mse': 3359902584012800.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the overall performance of the model\n",
    "demeaned_cv.compute_overall_performance(use_fold_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a13e40",
   "metadata": {},
   "source": [
    "# The Delta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71ebe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable\n",
    "delta_target_var = 'log_mean_pc_cons_usd_2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de7ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image statistics for the demeaned images\n",
    "delta_img_stats = get_agg_img_stats(delta_stats_pth, delta_df, id_var = 'delta_id')\n",
    "delta_feat_stats = get_feat_stats(delta_img_stats)\n",
    "\n",
    "# get the target stats\n",
    "delta_target_stats = get_target_stats(delta_df, delta_target_var)\n",
    "\n",
    "# define the transforms\n",
    "# get the data transforms for the target --> is used in the DataLoader object\n",
    "delta_target_transform = transforms.Compose([\n",
    "        torchvision.transforms.Lambda(lambda t: torch_standardise(t, delta_target_stats['mean'], delta_target_stats['std'])),\n",
    "    ])\n",
    "\n",
    "# get the data transform for the Landsat image (normalisation and random horizontal + vertical flips)\n",
    "delta_feat_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomVerticalFlip(.5),\n",
    "    torchvision.transforms.RandomHorizontalFlip(.5),\n",
    "    transforms.Normalize(delta_feat_stats['mean'], delta_feat_stats['std'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd315bb",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faef2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'within_cons_delta'\n",
    "cv_object_name = 'within_cons_delta_cv'\n",
    "data_type = 'RS_v2'\n",
    "id_var = 'delta_id'\n",
    "\n",
    "# set settings for the ResNet\n",
    "input_channels = 4\n",
    "ms = False\n",
    "random_weights = True\n",
    "\n",
    "# set hyper-parameters\n",
    "hyper_params = {\n",
    "    'lr': 1e-2,\n",
    "    'batch_size': 128,\n",
    "    'alpha': 1e-2,\n",
    "    'step_size': 1,\n",
    "    'gamma': 0.96,\n",
    "    'n_epochs': n_epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10b6a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into RAM first\n",
    "# this reduces training times by ~60%...\n",
    "_dat = SatDataset(delta_df, delta_img_dir, data_type,\n",
    "                  delta_target_var, id_var,\n",
    "                  delta_feat_transform, delta_target_transform)\n",
    "_loader = DataLoader(_dat, batch_size = hyper_params['batch_size'], shuffle = False)\n",
    "_, _ = next(iter(_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37374d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7465f83553104f968b700f61b5b8451f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 0\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4774f3d81d5d4770b40f467be77fd748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 2.0793 - Train R2 -0.3739 - Val MSE: 10065925598196269056.0000 - Val R2 -37539036359982571520.0000\n",
      "\tEPOCH 1 - Train MSE: 558.6413 - Train R2 -368.1187 - Val MSE: 945620399423488.0000 - Val R2 -3526519057229571.0000\n",
      "Finished training after 59 seconds\n",
      "Lowest loss on validation set in epoch 1: 945620399423488.000000\n",
      "Maximum R2 on validation set in epoch 1: -3526519057229571.000000\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24d7f81814f437fa972d12b601d526e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 1\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d71429383a4c158c5951d22bb8ac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 1.1245 - Train R2 -0.5992 - Val MSE: 12966173389478690816.0000 - Val R2 -14731146685712551936.0000\n",
      "\tEPOCH 1 - Train MSE: 647.5916 - Train R2 -919.9939 - Val MSE: 949644381126656.0000 - Val R2 -1078911262110028.8750\n",
      "Finished training after 58 seconds\n",
      "Lowest loss on validation set in epoch 1: 949644381126656.000000\n",
      "Maximum R2 on validation set in epoch 1: -1078911262110028.875000\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7432c6ce60b48ea9ab774349b66011a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Cross-validation after 148 seconds\n"
     ]
    }
   ],
   "source": [
    "# initialise the model and the CrossValidator object\n",
    "ResNet18 = init_resnet(input_channels, ms, random_weights, random_seed = random_seed)\n",
    "delta_cv = CrossValidator(model = ResNet18,\n",
    "                       lsms_df = delta_df,\n",
    "                       fold_ids = fold_ids,\n",
    "                       img_dir = delta_img_dir,\n",
    "                       data_type = data_type,\n",
    "                       target_var = delta_target_var,\n",
    "                       id_var = id_var,\n",
    "                       feat_transform = delta_feat_transform,\n",
    "                       target_transform = delta_target_transform,\n",
    "                       device = device,\n",
    "                       model_name = model_name,\n",
    "                       random_seed = random_seed)\n",
    "\n",
    "# run k-fold-cv\n",
    "delta_cv.run_cv(hyper_params)\n",
    "\n",
    "# save the cv object\n",
    "delta_cv.save_object(name = cv_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76dc949b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -2480164330503185.5, 'mse': 2266446793015296.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the overall performance of the model\n",
    "delta_cv.compute_overall_performance(use_fold_weights = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
