{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853cec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e303e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the torch_framework package\n",
    "from analysis_utils.torch_framework.CrossValidator import CrossValidator\n",
    "from analysis_utils.torch_framework.ResNet18 import *\n",
    "from analysis_utils.torch_framework.torch_helpers import *\n",
    "from analysis_utils.torch_framework.SatDataset import SatDataset\n",
    "from analysis_utils.torch_framework.BetweenModel import BetweenModel\n",
    "\n",
    "# load the variable names of the tabular feature data\n",
    "from analysis_utils.variable_names import *\n",
    "\n",
    "# load the functions to do spatial CV\n",
    "from analysis_utils.spatial_CV import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2174eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    }
   ],
   "source": [
    "# set the global file paths\n",
    "root_data_dir = \"../../Data\"\n",
    "\n",
    "# the lsms data\n",
    "lsms_pth = f\"{root_data_dir}/lsms/processed/labels_cluster_v1.csv\"\n",
    "\n",
    "# the feature data (OSM + precipitation)\n",
    "feat_data_pth = f\"{root_data_dir}/feature_data/tabular_data.csv\"\n",
    "\n",
    "# set the random seed\n",
    "random_seed = 348\n",
    "\n",
    "# set the number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# set the number of epochs\n",
    "n_epochs = 2\n",
    "\n",
    "# training device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76013e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths for the satellite image satistics\n",
    "sat_img_dir = f\"{root_data_dir}/satellite_imgs\"\n",
    "\n",
    "# median LS images at the cluster level\n",
    "LS_median_img_dir = f\"{sat_img_dir}/LS/LS_median_cluster\"\n",
    "LS_median_stats_pth = f\"{sat_img_dir}/LS/LS_median_img_stats.pkl\"\n",
    "\n",
    "# the RS v2 images at the cluster level\n",
    "RS_v2_between_img_dir = f\"{sat_img_dir}/RS_v2/RS_v2_between\"\n",
    "RS_v2_between_stats_pth = f\"{sat_img_dir}/RS_v2/RS_v2_between_img_stats.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9e6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the LSMS data and the feature data (OSM and precipitation)\n",
    "lsms_df = pd.read_csv(lsms_pth).iloc[:100,:]\n",
    "feat_df = pd.read_csv(feat_data_pth)\n",
    "\n",
    "# add the mean variable at the cluster level\n",
    "lsms_df['avg_log_mean_pc_cons_usd_2017'] = lsms_df.groupby('cluster_id')['log_mean_pc_cons_usd_2017'].transform('mean')\n",
    "\n",
    "# merge the lsms_df and the feat_df\n",
    "df = pd.merge(lsms_df, feat_df, on = ('unique_id','cluster_id'), how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766aeb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, specified test ratio: 0.2 - Actual test ratio 0.22\n",
      "Fold 1, specified test ratio: 0.2 - Actual test ratio 0.22\n",
      "Fold 2, specified test ratio: 0.2 - Actual test ratio 0.25\n",
      "Fold 3, specified test ratio: 0.2 - Actual test ratio 0.22\n",
      "Fold 4, specified test ratio: 0.2 - Actual test ratio 0.08\n"
     ]
    }
   ],
   "source": [
    "# divide the data into k different folds\n",
    "fold_ids = split_lsms_spatial(lsms_df, n_folds = n_folds, random_seed = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0647b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable\n",
    "between_target_var = 'avg_log_mean_pc_cons_usd_2017'\n",
    "\n",
    "# define the tabular x_vars to keep in the data\n",
    "between_x_vars = osm_dist_vars + osm_count_vars + ['avg_precipitation']\n",
    "\n",
    "# define the mean cluster dataset\n",
    "between_df = df[['cluster_id', 'lat', 'lon', 'country', between_target_var] + between_x_vars].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba0250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image statistics for the Landsat images for each band\n",
    "LS_img_stats = get_agg_img_stats(LS_median_stats_pth, between_df, id_var = 'cluster_id')\n",
    "RS_img_stats = get_agg_img_stats(RS_v2_between_stats_pth, between_df, id_var = 'cluster_id')\n",
    "\n",
    "# extract the relevant statistics for each band (i.e. the mean, std, min, max) and get them as a list\n",
    "LS_feat_stats = get_feat_stats(LS_img_stats) \n",
    "RS_feat_stats = get_feat_stats(RS_img_stats)\n",
    "\n",
    "# For the RS feat stats, alter the mean and std of the last two channels (WSF and ESA LC)\n",
    "# For these two channels normalisation does not introduce any advantage or yields meaningless numbers\n",
    "# Thus just set mean and std for both channels to 0 and 1 (which effectively avoids normalisation)\n",
    "RS_feat_stats['mean'][-2:] = [0,0]\n",
    "RS_feat_stats['std'][-2:] = [1,1]\n",
    "\n",
    "# get the stats for the target variable\n",
    "between_target_stats = get_target_stats(df, between_target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf92cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data transforms for the target --> is used in the DataLoader object\n",
    "target_transform = transforms.Compose([\n",
    "        torchvision.transforms.Lambda(lambda t: standardise(t, between_target_stats['mean'], between_target_stats['std'])),\n",
    "    ])\n",
    "\n",
    "# get the data transform for the Landsat image (normalisation and random horizontal + vertical flips)\n",
    "LS_transforms = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomVerticalFlip(.5),\n",
    "    torchvision.transforms.RandomHorizontalFlip(.5),\n",
    "    transforms.Normalize(LS_feat_stats['mean'], LS_feat_stats['std'])]\n",
    ")\n",
    "\n",
    "# same for RS:\n",
    "RS_transforms = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.RandomVerticalFlip(.5),\n",
    "    torchvision.transforms.RandomHorizontalFlip(.5),\n",
    "    transforms.Normalize(RS_feat_stats['mean'], RS_feat_stats['std'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3c506",
   "metadata": {},
   "source": [
    "## Run the Landsat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b594c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'between_cons_LS'\n",
    "cv_object_name = 'between_cons_LS_cv'\n",
    "data_type = 'LS'\n",
    "id_var = 'cluster_id'\n",
    "\n",
    "# set settings for the ResNet\n",
    "input_channels = 6\n",
    "ms = True\n",
    "random_weights = False\n",
    "\n",
    "# set hyper-parameters\n",
    "hyper_params = {\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 128,\n",
    "    'alpha': 0,\n",
    "    'step_size': 1,\n",
    "    'gamma': 0.96,\n",
    "    'n_epochs': n_epochs\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ace1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into RAM first\n",
    "# this reduces training times by ~60%...\n",
    "_dat = SatDataset(between_df, LS_median_img_dir, data_type, between_target_var, id_var,\n",
    "                  LS_transforms, target_transform)\n",
    "_loader = DataLoader(_dat, batch_size = hyper_params['batch_size'], shuffle = False)\n",
    "_, _ = next(iter(_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75229242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b4f88d9014a3d91a84624544493b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 0\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84d75c1564245a2b44d7eb6ba2faf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 3.5425 - Train R2 -2.2749 - Val MSE: 26.2618 - Val R2 -31.3995\n",
      "\tEPOCH 1 - Train MSE: 20.3883 - Train R2 -17.8482 - Val MSE: 66.7920 - Val R2 -81.4021\n",
      "Finished training after 16 seconds\n",
      "Lowest loss on validation set in epoch 0: 26.261824\n",
      "Maximum R2 on validation set in epoch 0: -31.399537\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46ed8de2dc74381aecd662e72bad743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 1\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b94af55eaf4733b0f5a88285df5614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 3.0672 - Train R2 -1.5969 - Val MSE: 1.8405 - Val R2 -1.5686\n",
      "\tEPOCH 1 - Train MSE: 19.5629 - Train R2 -15.5635 - Val MSE: 25.1064 - Val R2 -34.0398\n",
      "Finished training after 17 seconds\n",
      "Lowest loss on validation set in epoch 0: 1.840458\n",
      "Maximum R2 on validation set in epoch 0: -1.568635\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d276d4bd8854fa78fb709709cd50a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 2\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f9fd09763b47049d19a7f61f4221d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 2.0667 - Train R2 -1.3565 - Val MSE: 9.7342 - Val R2 -7.2553\n",
      "\tEPOCH 1 - Train MSE: 33.0528 - Train R2 -36.6879 - Val MSE: 105.0355 - Val R2 -88.0768\n",
      "Finished training after 16 seconds\n",
      "Lowest loss on validation set in epoch 0: 9.734236\n",
      "Maximum R2 on validation set in epoch 0: -7.255258\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1617b49b798447ea9b53b3fe78aa4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 3\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b2ea0640ec43bba55294297ef013f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 3.2345 - Train R2 -1.8237 - Val MSE: 11.6959 - Val R2 -9.6652\n",
      "\tEPOCH 1 - Train MSE: 19.1163 - Train R2 -15.6888 - Val MSE: 55.4577 - Val R2 -49.5706\n",
      "Finished training after 17 seconds\n",
      "Lowest loss on validation set in epoch 0: 11.695909\n",
      "Maximum R2 on validation set in epoch 0: -9.665236\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf58bee362a042c584f0cdda4641a11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 4\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b39ea61b3a415ca5fc77b8a7f7ddf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 3.9094 - Train R2 -3.0115 - Val MSE: 2.4478 - Val R2 -2.0514\n",
      "\tEPOCH 1 - Train MSE: 29.4754 - Train R2 -29.2446 - Val MSE: 40.2339 - Val R2 -49.1543\n",
      "Finished training after 20 seconds\n",
      "Lowest loss on validation set in epoch 0: 2.447798\n",
      "Maximum R2 on validation set in epoch 0: -2.051353\n",
      "Predicting values\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018ab6350b044465bde5292611a688f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Cross-validation after 90 seconds\n"
     ]
    }
   ],
   "source": [
    "# initialise the model and the CrossValidator object\n",
    "ResNet18 = init_resnet(input_channels, ms, random_weights, random_seed = random_seed)\n",
    "ls_cv = CrossValidator(model = ResNet18, \n",
    "                       lsms_df = between_df, \n",
    "                       fold_ids = fold_ids,\n",
    "                       img_dir = LS_median_img_dir, \n",
    "                       data_type = data_type, \n",
    "                       target_var = between_target_var,\n",
    "                       id_var = id_var,\n",
    "                       feat_transform = LS_transforms, \n",
    "                       target_transform = target_transform,\n",
    "                       device = device,\n",
    "                       model_name = model_name,\n",
    "                       random_seed = random_seed)\n",
    "\n",
    "# run k-fold-cv\n",
    "ls_cv.run_cv(hyper_params)\n",
    "\n",
    "# save the cv object\n",
    "ls_cv.save_object(name = cv_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1120b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-31.3995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-31.3995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4105bea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -12.6599205087245, 'mse': 9.690663178761799}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the overall performance of the model\n",
    "ls_cv.compute_overall_performance(use_fold_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31870376",
   "metadata": {},
   "source": [
    "## Run the RS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826659d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'between_cons_RS'\n",
    "cv_object_name = 'between_cons_RS_cv'\n",
    "data_type = 'RS_v2'\n",
    "id_var = 'cluster_id'\n",
    "img_dir = RS_v2_between_img_dir\n",
    "\n",
    "# set settings for the ResNet\n",
    "input_channels = 6\n",
    "ms = False\n",
    "random_weights = True\n",
    "\n",
    "# set hyper-parameters\n",
    "hyper_params = {\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 128,\n",
    "    'alpha': 0,\n",
    "    'step_size': 1,\n",
    "    'gamma': 0.96,\n",
    "    'n_epochs': n_epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4394188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into RAM first\n",
    "# this reduces training times by ~60%...\n",
    "_dat = SatDataset(between_df, img_dir, data_type, between_target_var, id_var,\n",
    "                  RS_transforms, target_transform)\n",
    "_loader = DataLoader(_dat, batch_size = hyper_params['batch_size'], shuffle = False)\n",
    "_, _ = next(iter(_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171c885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1e1a77153144c8a18a047721f26633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 0\n",
      "Initialising training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538bf3ad01ea4bf4b6bc4c51d2b66c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEPOCH 0 - Train MSE: 2.0872 - Train R2 -0.9295 - Val MSE: 861281.3750 - Val R2 -1062572.5152\n"
     ]
    }
   ],
   "source": [
    "# initialise the model and the CrossValidator object\n",
    "ResNet18 = init_resnet(input_channels, ms, random_weights, random_seed = random_seed)\n",
    "rs_cv = CrossValidator(model = ResNet18, \n",
    "                       lsms_df = between_df, \n",
    "                       fold_ids = fold_ids,\n",
    "                       img_dir = img_dir, \n",
    "                       data_type = data_type, \n",
    "                       target_var = between_target_var,\n",
    "                       id_var = id_var,\n",
    "                       feat_transform = RS_transforms, \n",
    "                       target_transform = target_transform,\n",
    "                       device = device,\n",
    "                       model_name = model_name,\n",
    "                       random_seed = random_seed)\n",
    "\n",
    "# run k-fold-cv\n",
    "rs_cv.run_cv(hyper_params)\n",
    "\n",
    "# save the cv object\n",
    "rs_cv.save_object(name = cv_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the overall performance\n",
    "rs_cv.compute_overall_performance(use_fold_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632d80d",
   "metadata": {},
   "source": [
    "# Run the between model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Between model\n",
    "ls_cv_pth = \"../results/model_objects/between_cons_LS_cv.pkl\"\n",
    "rs_cv_pth = \"../results/model_objects/between_cons_RS_cv.pkl\"\n",
    "between_model = BetweenModel(ls_cv_pth, rs_cv_pth, between_df, between_target_var, \n",
    "                             between_x_vars, fold_ids, device, random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19851992",
   "metadata": {},
   "outputs": [],
   "source": [
    "between_model.train(min_samples_leaf = 10, n_components = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_cv.best_model_paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
